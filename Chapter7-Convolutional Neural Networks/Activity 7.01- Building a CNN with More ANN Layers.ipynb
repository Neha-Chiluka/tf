{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, \\\n",
    "    Dropout, GlobalMaxPooling2D, Activation, Rescaling\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"cifar10\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
    "    with_info=True,  # able to get info about dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = ds_info.features[\"image\"].shape\n",
    "print(f'Shape of Images in the Dataset: \\t{image_shape}')\n",
    "\n",
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "print(f'Number of Classes in the Dataset: \\t{num_classes}')\n",
    "\n",
    "names_of_classes = ds_info.features[\"label\"].names\n",
    "print(f'Names of Classes in the Dataset: \\t{names_of_classes}\\n')\n",
    "\n",
    "for name in names_of_classes:\n",
    "    print(f'Label for class \\\n",
    "          \"{name}\":  \\t\\t{ds_info.features[\"label\"].str2int(name)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total examples in Train Dataset: \\\n",
    "      \\t{len(ds_train)}')\n",
    "print(f'Total examples in Test Dataset: \\\n",
    "      \\t{len(ds_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7026d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9eb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e385479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for test Dataset\n",
    "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_train.batch(128)\n",
    "ds_test = ds_train.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((32, 32, 3)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", strides=2),\n",
    "        layers.Conv2D(64, 3, activation='relu', strides=2),\n",
    "        layers.Conv2D(128, 3, activation='relu', strides=2),\n",
    "        layers.Flatten(),\n",
    "        Dropout(rate=0.5),\n",
    "        layers.Dense(1024, activation=\"relu\"),\n",
    "        Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(ds_train, validation_data=ds_test, epochs=15, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_trend_by_epoch(tr_values, val_values, title):\n",
    "        epoch_number = range(len(tr_values))\n",
    "        plt.plot(epoch_number, tr_values, 'r')\n",
    "        plt.plot(epoch_number, val_values, 'b')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.legend(['Training '+title, 'Validation '+title])\n",
    "        plt.figure()\n",
    "hist_dict = history.history\n",
    "tr_accuracy, val_accuracy = hist_dict['accuracy'], \\\n",
    "                                hist_dict['val_accuracy']\n",
    "plot_trend_by_epoch(tr_accuracy, val_accuracy, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss, val_loss = hist_dict['loss'], hist_dict['val_loss']\n",
    "plot_trend_by_epoch(tr_loss, val_loss, \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ddeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_labels = []\n",
    "test_images = []\n",
    "for image, label in tfds.as_numpy(ds_test.unbatch()):\n",
    "        test_images.append(image)\n",
    "        test_labels.append(label)\n",
    "test_labels = np.array(test_labels)\n",
    "predictions = model.predict\\\n",
    "                  (ds_test).argmax(axis=1)\n",
    "incorrect_predictions = np.where(predictions != test_labels)[0]\n",
    "index = np.random.choice(incorrect_predictions)\n",
    "plt.imshow(test_images[index])\n",
    "print(f'True label: {names_of_classes[test_labels[index]]}')\n",
    "print(f'Predicted label: {names_of_classes[predictions[index]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d7b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a903cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a36bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588e094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
